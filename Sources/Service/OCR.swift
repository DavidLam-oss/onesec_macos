//
//  OCR.swift
//  OnesecCore
//
//  Created by AI Assistant on 2025/10/27.
//

import Cocoa
import CoreGraphics
@preconcurrency import Vision

// MARK: - è¯†åˆ«ç»“æœ

struct RecognizedText {
    let text: String
    let boundingBox: CGRect // å½’ä¸€åŒ–åæ ‡ (0.0-1.0)
}

// MARK: - OCRæœåŠ¡

class OCRService {
    /// æˆªå–å‰å°çª—å£å¹¶è¯†åˆ«æ–‡å­—
    static func captureFrontWindowAndRecognize() async -> [RecognizedText] {
        guard let windowImage = captureFrontWindow() else {
            log.error("æ— æ³•æˆªå–å‰å°çª—å£")
            return []
        }
        
        return await recognizeText(from: windowImage)
    }
    
    /// è·å–å‰å°çª—å£çš„çº¯æ–‡æœ¬å†…å®¹
    static func captureFrontWindowText() async -> String {
        let results = await captureFrontWindowAndRecognize()
        return results.map(\.text).joined(separator: "\n")
    }
    
    /// ä¿å­˜è¯†åˆ«ç»“æœåˆ°æ¡Œé¢txtæ–‡ä»¶
    static func saveToDesktop(_ results: [RecognizedText]) {
        let timestamp = DateFormatter().apply {
            $0.dateFormat = "yyyyMMdd_HHmmss"
        }.string(from: Date())
        
        let filename = "OCR_\(timestamp).txt"
        let desktopPath = FileManager.default.homeDirectoryForCurrentUser
            .appendingPathComponent("Desktop")
            .appendingPathComponent(filename)
        
        let content = results.enumerated().map { index, result in
            "[\(index + 1)] \(result.text) (x:\(String(format: "%.3f", result.boundingBox.origin.x)), y:\(String(format: "%.3f", result.boundingBox.origin.y)))"
        }.joined(separator: "\n")
        
        try? content.write(to: desktopPath, atomically: true, encoding: .utf8)
        log.info("ğŸ“„ OCRç»“æœå·²ä¿å­˜: \(desktopPath.path)")
    }
    
    // MARK: - Private Methods
    
    /// è·å–å‰å°çª—å£çš„æˆªå›¾
    private static func captureFrontWindow() -> CGImage? {
        // 1. è·å–çª—å£åˆ—è¡¨
        guard let windowList = CGWindowListCopyWindowInfo([.optionOnScreenOnly, .excludeDesktopElements], kCGNullWindowID) as? [[String: Any]] else {
            log.error("ğŸ” DEBUG: æ— æ³•è·å–çª—å£åˆ—è¡¨ (CGWindowListCopyWindowInfo å¤±è´¥)")
            return nil
        }
        log.debug("ğŸ” DEBUG: æˆåŠŸè·å–çª—å£åˆ—è¡¨ï¼Œå…± \(windowList.count) ä¸ªçª—å£")
        
        // 2. è·å–å‰å°åº”ç”¨
        guard let frontApp = NSWorkspace.shared.frontmostApplication else {
            log.error("ğŸ” DEBUG: æ— æ³•è·å–å‰å°åº”ç”¨ (NSWorkspace.shared.frontmostApplication ä¸º nil)")
            return nil
        }
        
        let frontPID = frontApp.processIdentifier
        let frontAppName = frontApp.localizedName ?? "Unknown"
        log.debug("ğŸ” DEBUG: å‰å°åº”ç”¨: \(frontAppName) (PID: \(frontPID))")
        
        // 3. æ‰¾åˆ°å‰å°åº”ç”¨çš„ä¸»çª—å£
        var matchedWindowsCount = 0
        for (index, window) in windowList.enumerated() {
            let ownerPID = window[kCGWindowOwnerPID as String] as? Int32
            let windowLayer = window[kCGWindowLayer as String] as? Int
            let bounds = window[kCGWindowBounds as String] as? [String: CGFloat]
            
            // è°ƒè¯•ï¼šæ‰“å°å‰5ä¸ªçª—å£çš„ä¿¡æ¯
            if index < 5 {
                log.debug("ğŸ” DEBUG: çª—å£[\(index)] PID=\(ownerPID ?? -1), Layer=\(windowLayer ?? -1), Bounds=\(bounds != nil ? "æœ‰" : "æ— ")")
            }
            
            // æ£€æŸ¥æ˜¯å¦å±äºå‰å°åº”ç”¨
            guard let pid = ownerPID, pid == frontPID else {
                continue
            }
            
            matchedWindowsCount += 1
            log.debug("ğŸ” DEBUG: æ‰¾åˆ°åŒ¹é…çš„çª—å£ #\(matchedWindowsCount), Layer=\(windowLayer ?? -1)")
            
            // æ£€æŸ¥çª—å£å±‚çº§
            guard let layer = windowLayer, layer == 0 else {
                log.debug("ğŸ” DEBUG: è·³è¿‡çª—å£ï¼ˆLayer ä¸æ˜¯ 0ï¼‰")
                continue
            }
            
            // æ£€æŸ¥è¾¹ç•Œ
            guard let windowBounds = bounds,
                  let x = windowBounds["X"],
                  let y = windowBounds["Y"],
                  let width = windowBounds["Width"],
                  let height = windowBounds["Height"] else {
                log.debug("ğŸ” DEBUG: è·³è¿‡çª—å£ï¼ˆæ— æ³•è·å–è¾¹ç•Œä¿¡æ¯ï¼‰")
                continue
            }
            
            // æ£€æŸ¥å°ºå¯¸
            guard width > 100, height > 100 else {
                log.debug("ğŸ” DEBUG: è·³è¿‡çª—å£ï¼ˆå°ºå¯¸å¤ªå°: \(Int(width))x\(Int(height))ï¼‰")
                continue
            }
            
            let windowRect = CGRect(x: x, y: y, width: width, height: height)
            log.info("ğŸ“¸ æˆªå–å‰å°çª—å£: \(frontAppName) - å°ºå¯¸: \(Int(width))x\(Int(height))")
            
            // 4. åˆ›å»ºæˆªå›¾
            guard let image = CGDisplayCreateImage(CGMainDisplayID(), rect: windowRect) else {
                log.error("ğŸ” DEBUG: CGDisplayCreateImage å¤±è´¥ï¼ˆrect: \(windowRect)ï¼‰")
                continue
            }
            
            log.debug("ğŸ” DEBUG: æˆåŠŸåˆ›å»ºçª—å£æˆªå›¾")
            return image
        }
        
        log.warning("ğŸ” DEBUG: æœªæ‰¾åˆ°å‰å°åº”ç”¨çš„æœ‰æ•ˆçª—å£ï¼ˆå…±æ‰¾åˆ° \(matchedWindowsCount) ä¸ªåŒ¹é… PID çš„çª—å£ï¼‰ï¼Œå›é€€åˆ°å…¨å±æˆªå›¾")
        
        // 5. å›é€€åˆ°å…¨å±æˆªå›¾
        guard let fullScreenImage = CGDisplayCreateImage(CGMainDisplayID()) else {
            log.error("ğŸ” DEBUG: å…¨å±æˆªå›¾ä¹Ÿå¤±è´¥äº†ï¼å¯èƒ½æ²¡æœ‰å±å¹•å½•åˆ¶æƒé™")
            return nil
        }
        
        log.debug("ğŸ” DEBUG: ä½¿ç”¨å…¨å±æˆªå›¾")
        return fullScreenImage
    }
    
    /// ä»å›¾åƒè¯†åˆ«æ–‡å­—
    private static func recognizeText(from image: CGImage) async -> [RecognizedText] {
        await withCheckedContinuation { continuation in
            let request = VNRecognizeTextRequest { request, error in
                if let error {
                    log.error("OCRè¯†åˆ«å¤±è´¥: \(error.localizedDescription)")
                    continuation.resume(returning: [])
                    return
                }
                
                guard let observations = request.results as? [VNRecognizedTextObservation] else {
                    continuation.resume(returning: [])
                    return
                }
                
                let results = observations.compactMap { observation -> RecognizedText? in
                    guard let candidate = observation.topCandidates(1).first else {
                        return nil
                    }
                    return RecognizedText(text: candidate.string, boundingBox: observation.boundingBox)
                }
                
                log.info("OCRè¯†åˆ«å®Œæˆï¼Œå…±è¯†åˆ« \(results.count) ä¸ªæ–‡æœ¬å—")
                continuation.resume(returning: results)
            }
            
            // é…ç½®è¯†åˆ«å‚æ•°
            request.recognitionLevel = .accurate
            request.usesLanguageCorrection = true
            request.recognitionLanguages = ["zh-Hans", "zh-Hant", "en-US"]
            
            // æ‰§è¡Œè¯†åˆ«
            let handler = VNImageRequestHandler(cgImage: image, options: [:])
            DispatchQueue.global(qos: .userInitiated).async {
                do {
                    try handler.perform([request])
                } catch {
                    log.error("OCRè¯·æ±‚æ‰§è¡Œå¤±è´¥: \(error.localizedDescription)")
                    continuation.resume(returning: [])
                }
            }
        }
    }
}

// MARK: - Helper Extension

private extension DateFormatter {
    func apply(_ closure: (DateFormatter) -> Void) -> DateFormatter {
        closure(self)
        return self
    }
}
