//
//  AudioSinkNodeRecorder.swift
//  OnesecCore
//
//  Created by ç‹æ™“é›¨ on 2025/10/15.
//

import AVFoundation
import Foundation

enum RecordState {
    case idle
    case recording
    case processing
    case stopping
}

class AudioSinkNodeRecorder {
    private var audioEngine = AVAudioEngine()
    private var sinkNode: AVAudioSinkNode!
    private var converter: AVAudioConverter!
    
    private var recordState: RecordState = .idle
    private var bufferCount = 0
    private var firstBufferTime: Date?
    private var pendingAudioBuffers: [Data] = []
    
    // å½•éŸ³ç»Ÿè®¡æ•°æ®
    private var totalPacketsSent = 0
    private var totalBytesSent = 0
    private var recordingStartTime: Date?
    
    // è¯†åˆ«ç»“æœå­˜å‚¨
    private var recognitionResults: [String] = []
    private var currentRecognitionText: String = ""
    
    // ç›®æ ‡æ ¼å¼
    private let targetFormat: AVAudioFormat = .init(settings: [
        AVFormatIDKey: Int(kAudioFormatLinearPCM),
        AVSampleRateKey: 16000.0,
        AVNumberOfChannelsKey: 1,
        AVLinearPCMBitDepthKey: 16,
        AVLinearPCMIsBigEndianKey: false,
        AVLinearPCMIsFloatKey: false,
        AVLinearPCMIsNonInterleaved: false
    ])!
    
    init() {
        setupSinkNodeAudioEngine()
    }
    
    private func setupSinkNodeAudioEngine() {
        let inputNode = audioEngine.inputNode
        let inputFormat = inputNode.outputFormat(forBus: 0)
        
        log.debug("è¾“å…¥æ ¼å¼: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount)å£°é“")
        log.debug("ç›®æ ‡æ ¼å¼: \(targetFormat.sampleRate)Hz, \(targetFormat.channelCount)å£°é“")
        
        guard let audioConverter = AVAudioConverter(from: inputFormat, to: targetFormat) else {
            log.error("æ— æ³•åˆ›å»ºéŸ³é¢‘æ ¼å¼è½¬æ¢å™¨")
            return
        }
        audioConverter.sampleRateConverterQuality = AVAudioQuality.high.rawValue
        converter = audioConverter
        
        // SinkNode Handle
        sinkNode = AVAudioSinkNode { [weak self] timestamp, frameCount, audioBufferList in
            guard let self, recordState == .recording else { return OSStatus(noErr) }
            processSinkNodeBuffer(audioBufferList, frameCount: frameCount, timestamp: timestamp)
            return OSStatus(noErr)
        }
        
        // è¿æ¥éŸ³é¢‘å›¾
        audioEngine.attach(sinkNode)
        audioEngine.connect(inputNode, to: sinkNode, format: inputFormat)
        
        log.info("âœ… SinkNode éŸ³é¢‘å¼•æ“è®¾ç½®å®Œæˆ")
    }
    
    /// å¤„ç†SinkNodeæ¥æ”¶åˆ°çš„éŸ³é¢‘ç¼“å†²åŒº
    private func processSinkNodeBuffer(_ audioBufferList: UnsafePointer<AudioBufferList>,
                                       frameCount: AVAudioFrameCount,
                                       timestamp: UnsafePointer<AudioTimeStamp>)
    {
        // è®°å½•ç¬¬ä¸€ä¸ªç¼“å†²åŒºæ—¶é—´
        if firstBufferTime == nil {
            firstBufferTime = Date()
        }
        
        bufferCount += 1
        
        // è·å–è¾“å…¥æ ¼å¼
        let inputFormat = audioEngine.inputNode.outputFormat(forBus: 0)
        
        // åˆ›å»ºè¾“å…¥ç¼“å†²åŒº
        guard let inputBuffer = AVAudioPCMBuffer(pcmFormat: inputFormat, frameCapacity: frameCount) else {
            return
        }
        inputBuffer.frameLength = frameCount
        
        // å¤åˆ¶éŸ³é¢‘æ•°æ® - ä»UnsafePointerè¯»å–
        let audioBuffer = audioBufferList.pointee.mBuffers
        let bytesToCopy = Int(audioBuffer.mDataByteSize)
        
        // ç¡®ä¿è¾“å…¥ç¼“å†²åŒºæœ‰æœ‰æ•ˆçš„æ•°æ®æŒ‡é’ˆ
        guard let inputData = inputBuffer.audioBufferList.pointee.mBuffers.mData,
              let sourceData = audioBuffer.mData
        else {
            log.error("éŸ³é¢‘ç¼“å†²åŒºæ•°æ®æŒ‡é’ˆä¸ºç©º")
            return
        }
        
        memcpy(inputData, sourceData, bytesToCopy)
        convertAndSendBuffer(inputBuffer)
    }
    
    /// è½¬æ¢å¹¶å‘é€éŸ³é¢‘ç¼“å†²åŒº
    private func convertAndSendBuffer(_ inputBuffer: AVAudioPCMBuffer) {
        // è®¡ç®—è¾“å‡ºå¸§æ•°
        let sampleRateRatio = targetFormat.sampleRate / inputBuffer.format.sampleRate
        let expectedOutputFrames = AVAudioFrameCount(Double(inputBuffer.frameLength) * sampleRateRatio)
        
        // åˆ›å»ºè¾“å‡ºç¼“å†²åŒº - åªåˆ†é…éœ€è¦çš„å®¹é‡ï¼Œé¿å…æµªè´¹
        guard let outputBuffer = AVAudioPCMBuffer(pcmFormat: targetFormat, frameCapacity: expectedOutputFrames) else {
            return
        }
        
        // æ‰§è¡Œæ ¼å¼è½¬æ¢
        var error: NSError?
        let status = converter.convert(to: outputBuffer, error: &error) { _, outStatus in
            outStatus.pointee = .haveData
            return inputBuffer
        }

        if status == .error {
            log.error("éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥: \(error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
            return
        }
        
        // ç¡®ä¿è¾“å‡ºç¼“å†²åŒºçš„ frameLength æ­£ç¡®è®¾ç½®
        if outputBuffer.frameLength == 0, expectedOutputFrames > 0 {
            outputBuffer.frameLength = expectedOutputFrames
        }
        
        // è®¡ç®—éŸ³é‡å¹¶å‘é€åˆ°UDS
        if recordState == .recording {
            let volume = calculateVolume(from: outputBuffer)
            EventBus.shared.publish(.volumeChanged(volume: volume))
        }
        
        // è½¬æ¢ä¸ºæ•°æ®å¹¶å‘é€
        let audioData = convertBufferToData(outputBuffer)
        if !audioData.isEmpty {
            if recordState == .recording {
                sendAudioData(audioData)
            } else if recordState == .stopping {
                pendingAudioBuffers.append(audioData)
            }
        }
    }
    
    /// å°†éŸ³é¢‘ç¼“å†²åŒºè½¬æ¢ä¸ºData
    private func convertBufferToData(_ buffer: AVAudioPCMBuffer) -> Data {
        guard buffer.frameLength > 0,
              let audioBuffer = buffer.audioBufferList.pointee.mBuffers.mData
        else {
            return Data()
        }
        
        // ä½¿ç”¨å®é™…å¸§é•¿åº¦è®¡ç®—æ•°æ®å¤§å°ï¼Œè€Œä¸æ˜¯ç¼“å†²åŒºæ€»å®¹é‡
        let bytesPerFrame = Int(buffer.format.streamDescription.pointee.mBytesPerFrame)
        let actualDataSize = Int(buffer.frameLength) * bytesPerFrame
        
        return Data(bytes: audioBuffer, count: actualDataSize)
    }
    
    /// å‘é€éŸ³é¢‘æ•°æ®
    private func sendAudioData(_ audioData: Data) {
        // æ›´æ–°ç»Ÿè®¡æ•°æ®
        totalPacketsSent += 1
        totalBytesSent += audioData.count
        
        EventBus.shared.publish(.audioDataReceived(data: audioData))
    }
    
    // MARK: -

    func startRecording(appInfo: AppInfo? = nil, focusContext: FocusContext? = nil, focusElementInfo: FocusElementInfo? = nil, recordMode: RecordMode = .normal) {
        guard recordState != .recording else {
            log.warning("Recording is in progress")
            return
        }
        
        guard ConnectionCenter.shared.isWssServerConnected() else {
            log.warning("Websocket Server not connected")
            // TODO: send event
            return
        }
        
        log.info("ğŸ™ï¸ å¼€å§‹å½•éŸ³...")
        
        // é‡ç½®çŠ¶æ€
        resetState()
        recordState = .recording
        EventBus.shared.publish(.recordingStarted(
            appInfo: appInfo,
            focusContext: focusContext,
            focusElementInfo: focusElementInfo,
            recordMode: recordMode
        ))
        
        do {
            try audioEngine.start()
        } catch {
            log.error("ğŸ™… å½•éŸ³å¯åŠ¨å¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    func stopRecording() {
        guard recordState == .recording else {
            log.warning("å½•éŸ³æœªåœ¨è¿›è¡Œä¸­")
            return
        }
        
        log.info("ğŸ›‘ åœæ­¢å½•éŸ³...")
        recordState = .stopping
        
        // åœæ­¢éŸ³é¢‘å¼•æ“
        audioEngine.stop()
        
        // å¤„ç†å¾…å‘é€çš„éŸ³é¢‘æ•°æ®
        for audioData in pendingAudioBuffers {
            sendAudioData(audioData)
        }
        pendingAudioBuffers.removeAll()
        EventBus.shared.publish(.recordingStopped)
        
        // è®¡ç®—å½•éŸ³ç»Ÿè®¡ä¿¡æ¯
        if let startTime = recordingStartTime {
            let duration = Date().timeIntervalSince(startTime)
            let avgPacketSize = totalPacketsSent > 0 ? Double(totalBytesSent) / Double(totalPacketsSent) : 0
            let packetsPerSecond = duration > 0 ? Double(totalPacketsSent) / duration : 0
            let bytesPerSecond = duration > 0 ? Double(totalBytesSent) / duration : 0
            
            log.info("ğŸ“Š å½•éŸ³ç»Ÿè®¡æŠ¥å‘Š:")
            log.info("   ğŸ“¦ æ€»åŒ…æ•°: \(totalPacketsSent) ä¸ª")
            log.info("   ğŸ“ æ€»æ•°æ®é‡: \(String(format: "%.2f", Double(totalBytesSent) / 1024.0)) KB (\(totalBytesSent) å­—èŠ‚)")
            log.info("   ğŸ¤¡ å½•éŸ³æ—¶é•¿: \(String(format: "%.2f", duration)) ç§’")
            log.info("   ğŸ“Š å¹³å‡åŒ…å¤§å°: \(String(format: "%.1f", avgPacketSize)) å­—èŠ‚")
            log.info("   ğŸ“ˆ å‘é€é¢‘ç‡: \(String(format: "%.1f", packetsPerSecond)) åŒ…/ç§’")
            log.info("   ğŸ“ˆ æ•°æ®é€Ÿç‡: \(String(format: "%.1f", bytesPerSecond / 1024.0)) KB/ç§’")
            
            // è®¡ç®—ç†è®ºæ•°æ®é‡å¯¹æ¯”
            let theoreticalBytes = Int(duration * 16000 * 2) // 16kHz * 2å­—èŠ‚/æ ·æœ¬
            let efficiency = Double(totalBytesSent) / Double(theoreticalBytes) * 100.0
            log.info("   ğŸ¯ æ•°æ®å®Œæ•´æ€§: \(String(format: "%.1f", efficiency))% (ç†è®º: \(String(format: "%.2f", Double(theoreticalBytes) / 1024.0)) KB)")
        }
        
        log.info("âœ… å½•éŸ³åœæ­¢")
    }
    
    func resetState() {
        // é‡ç½®çŠ¶æ€
        recordState = .idle
        bufferCount = 0
        firstBufferTime = nil
        pendingAudioBuffers.removeAll()
        
        // é‡ç½®ç»Ÿè®¡æ•°æ®
        totalPacketsSent = 0
        totalBytesSent = 0
        recordingStartTime = Date()
    }
    
    /// è·å–å½“å‰è¯†åˆ«ç»“æœ
    func getCurrentRecognitionText() -> String {
        currentRecognitionText
    }
    
    /// è·å–æ‰€æœ‰è¯†åˆ«ç»“æœ
    func getAllRecognitionResults() -> [String] {
        recognitionResults
    }
    
    /// è®¡ç®—éŸ³é¢‘ç¼“å†²åŒºçš„éŸ³é‡
    private func calculateVolume(from buffer: AVAudioPCMBuffer) -> Float {
        guard let audioBuffer = buffer.audioBufferList.pointee.mBuffers.mData else {
            return 0.0
        }
        
        let frameCount = Int(buffer.frameLength)
        let channelCount = Int(buffer.format.channelCount)
        let bytesPerSample = Int(buffer.format.streamDescription.pointee.mBytesPerFrame) / channelCount
        
        var sum: Float = 0.0
        
        if bytesPerSample == 2 { // 16-bit
            let samples = audioBuffer.assumingMemoryBound(to: Int16.self)
            for i in 0..<frameCount {
                let sample = Float(samples[i]) / Float(Int16.max)
                sum += sample * sample
            }
        } else if bytesPerSample == 4 { // 32-bit float
            let samples = audioBuffer.assumingMemoryBound(to: Float.self)
            for i in 0..<frameCount {
                sum += samples[i] * samples[i]
            }
        }
        
        let rms = sqrt(sum / Float(frameCount))
        return min(1.0, rms * 10.0) // æ”¾å¤§éŸ³é‡å¹¶é™åˆ¶åœ¨ 0-1 èŒƒå›´å†…
    }
}
